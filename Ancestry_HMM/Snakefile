
INDIVIDUALS_LIST = range(20,25)


#HARDCODEBAD
INDIVIDUALS_LIST2 = ["257", "227", "136", "285", "281"]


rule all:
    input:
        ahmm_input="ahmm_input_file_vcf.panel",
        ahmm_output=expand("posterior_files/{individual}_best_posterior.txt", individual=INDIVIDUALS_LIST2),
        scoring_over="scoring_over.done"


rule normalize_vcf:
    input:
        vcf="/home/projects2/MAAG/LAI_sim/read_simulation/variants/all_sample.vcf.gz",
        bcftools_path="/home/ctools/bcftools-1.13/bcftools"
    output:
        norm_vcf="norm.vcf.gz"
    shell:
        """
        nice -19 \
        {input.bcftools_path} norm -m -any {input.vcf} | bgzip > {output.norm_vcf}
        """

rule extract_sample_names:
    input:
        vcf="norm.vcf.gz"
    output:
        txt="sample_names.txt"
    shell:
        """
        bcftools query -l {input.vcf} > {output.txt}
        """

rule create_sample2pop:
    input:
        txt="sample_names.txt"
    output:
        tsv="sample2pop.txt"
    shell:
        """
        python3 -c "import pandas as pd; \
        sample_names = pd.read_csv('{input.txt}', header=None, names=['Sample']); \
        sample_names['Sample'] = sample_names['Sample'].astype(str); \
        sample_names['Sample'] = pd.to_numeric(sample_names['Sample'], errors='coerce').fillna(0).astype(int); \
        sample_names = sample_names.sort_values(by='Sample'); \
        statuses = ['CEU', 'YRI', 'CHB', 'KAR', 'admixed']; \
        sample_names['Status'] = [statuses[i // 5 % len(statuses)] for i in range(len(sample_names))]; \
        sample_names.to_csv('{output.tsv}', sep='\\t', index=False)"
        """

rule vcf_to_ahmm:
    input:
        norm_vcf="norm.vcf.gz",
        sample_map="sample2pop.txt",
        vcf2ahmm_script="vcf2ahmm_modified.py"
    output:
        ahmm_input="ahmm_input_file_vcf.panel"
    shell:
        """
        rm -f ahmm.ploidy
        nice -19 python3 {input.vcf2ahmm_script} -v <(zcat {input.norm_vcf}) -s {input.sample_map} -m 0 -g 1 > {output.ahmm_input}
        """

rule run_ahmm:
    input:
        ahmm_input="ahmm_input_file_vcf.panel",
        ahmm_exe="/home/people/s184284/tools/Ancestry_HMM/src/ancestry_hmm"
    output:
        posterior=expand("posterior_files/{individual}.posterior", individual=INDIVIDUALS_LIST),
        done_file=touch("ahmm_completed.done")
    shell:
        """
        nice -19 {input.ahmm_exe} -i {input.ahmm_input} -s ahmm.ploidy -a 4 0.17 0.33 0.5 0.  -p 0 12 -0.16 -p 1 12 -0.33 -p 2 12 -0.5 -p 3 12 -0.01
        mv 20.posterior posterior_files/
        mv 21.posterior posterior_files/
        mv 22.posterior posterior_files/
        mv 23.posterior posterior_files/
        mv 24.posterior posterior_files/
        touch {output.done_file}
        """

rule preprocess_extract_ids_and_rename:
    input:
        ahmm_complete="ahmm_completed.done"
    output:
        touch("ids_extracted.done"),
        files=expand("posterior_files/{individual}.posterior", individual=['136', '227', '257', '281', '285'])
    shell:
        """
        bash process_ids_and_rename.sh        
        # Signal completion
        touch {output}
        """


rule find_best_posterior:
    input:
        processed="ids_extracted.done",
        posterior_files=expand("posterior_files/{individual}.posterior", individual=['136', '227', '257', '281', '285'])
    output:
        expand("posterior_files/{individual}_best_posterior.txt", individual=['136', '227', '257', '281', '285'])
    run:
        translate_column = {
            "2,0,0,0": "CEU",
            "1,1,0,0": "CEU/YRI",
            "1,0,1,0": "CEU/CHB",
            "1,0,0,1": "CEU/KAR",
            "0,2,0,0": "YRI",
            "0,1,1,0": "YRI/CHB",
            "0,1,0,1": "YRI/KAR",
            "0,0,2,0": "CHB",
            "0,0,1,1": "CHB/KAR",
            "0,0,0,2": "KAR"
        }

        for individual_file in input.posterior_files:
            output_file = individual_file.replace(".posterior", "_best_posterior.txt")
            with open(individual_file, 'r') as infile, open(output_file, 'w') as outfile:
                header = infile.readline().strip().split('\t')
                outfile.write(f"{header[1]}\tAncestry\n")

                for line in infile:
                    parts = line.strip().split('\t')
                    if len(parts) > 2:
                        values = parts[2:]
                        max_value = max(values, key=lambda x: float(x))
                        max_index = values.index(max_value)

                        # Use the header directly to get the corresponding ancestry
                        barcode = header[max_index + 2]  # Correctly offset to match allele combinations
                        best_pop = translate_column.get(barcode, "Unknown")

                        outfile.write(f"{parts[1]}\t{best_pop}\n")
                    else:
                        outfile.write(line)





rule score_ancestry_estimation:
    input:
        truth="/home/projects/MAAG/msprime_deme/msprime/manual_admix/ancestral_intervals_theoretical.txt.gz",
        best_posterior="posterior_files/{individual}_best_posterior.txt"
    output:
        "scoring_files/{individual}_score.txt"
    shell:
        "python3 score_ancestry_estimation.py {input.truth} {input.best_posterior} {output}"



rule all_scores_done:
    input:
        expand("scoring_files/{individual}_score.txt", individual=['136', '227', '257', '281', '285'])
    output:
        "scoring_over.done"
    shell:
        """
        touch {output}
        """



